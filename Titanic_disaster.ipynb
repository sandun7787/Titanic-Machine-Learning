{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "371bdcf7-57b5-4cce-8586-2b6825b4669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Importing necessary libraries for data analysis, visualization, and modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f90a5d6-79ae-4e91-af53-e9e732d16932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading training data from a CSV file into a pandas DataFrame and displaying the first few rows\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Loading test data from a CSV file into a pandas DataFrame and displaying the first few rows\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Reading and displaying the first few rows of the training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf5e7d-f4c3-4cb5-a1df-28abc3f2c9d8",
   "metadata": {},
   "source": [
    "# Extracting PassengerId column from the test data to be used later for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd8c0399-3c5f-448b-b125-c327464cb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_passenger_ids = test_data[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6320ba-7edf-4525-8c9c-a79c4ee9d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "# Generating descriptive statistics for the training data and storing them in 'x'\n",
    "x = train_data.describe()\n",
    "print(x)\n",
    "\n",
    "# Generating descriptive statistics for the test data and storing them in 'y'\n",
    "y = test_data.describe()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd3de2-93fa-4fda-86cc-c349236d90b9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) and Data Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2abcc384-0a1b-40b5-9292-e492f9f27f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exploratory Data Analysis (EDA) and Data Cleaning function\n",
    "def explore_data(data):\n",
    "    # Displaying general information about the dataset\n",
    "    print(\"Data Info:\")\n",
    "    print(data.info())\n",
    "\n",
    "    # Checking for missing values\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    # Displaying summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(data.describe())\n",
    "\n",
    "    # Distribution of survival\n",
    "    print(\"\\nSurvival Distribution:\")\n",
    "    print(data['Survived'].value_counts())\n",
    "\n",
    "    # Correlation matrix\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    corr_matrix = data.corr()\n",
    "    print(corr_matrix)\n",
    "    corr_matrix[\"Survived\"].sort_values(ascending=False)\n",
    "    # Visualizing correlation matrix\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    \n",
    "    # Creating scatter matrix for selected attributes\n",
    "    attribute = [\"PassengerId\", \"Survived\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "    scatter_matrix(data[attribute], figsize=(12, 8))\n",
    "\n",
    "    # Displaying plots\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6e0ec-42a9-4f74-ae3b-b4e12ad5dead",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) and Data Cleaning function for test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e6038e-a57e-4875-8944-ce4f48c8cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exploratory Data Analysis (EDA) and Data Cleaning function for test set\n",
    "def explore_data_for_test_set(data):\n",
    "    # Displaying general information about the dataset\n",
    "    print(\"Data Info:\")\n",
    "    print(data.info())\n",
    "\n",
    "    # Checking for missing values\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    # Displaying summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(data.describe())\n",
    "\n",
    "    # Correlation matrix\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    corr_matrix = data.corr()\n",
    "    print(corr_matrix)\n",
    "    \n",
    "    # Visualizing correlation matrix\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    \n",
    "    # Creating scatter matrix for selected attributes\n",
    "    attribute = [\"PassengerId\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "    scatter_matrix(data[attribute], figsize=(12, 8))\n",
    "\n",
    "    # Displaying plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e88c4-5cd5-44ed-b570-a0d34c585fed",
   "metadata": {},
   "source": [
    "# Function to clean and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f831656b-180e-423d-8b72-41ac01c99320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop([\"Ticket\", \"PassengerId\", \"Name\", \"Cabin\"], axis=1)\n",
    "    \n",
    "    # Fill missing values\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
    "    data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47dca1bc-5f19-4293-8b86-b7f2488327a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Exploration:\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Survival Distribution:\n",
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Correlation Matrix:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Explore and clean training data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Data Exploration:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mexplore_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Cleaning the training data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m train_data \u001b[38;5;241m=\u001b[39m clean_data(train_data)\n",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m, in \u001b[0;36mexplore_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Correlation matrix\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCorrelation Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(corr_matrix)\n\u001b[0;32m     23\u001b[0m corr_matrix[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:10704\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10702\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10703\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10704\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  10706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10707\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1888\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1889\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1891\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1715\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "# Explore and clean training data\n",
    "print(\"Training Data Exploration:\")\n",
    "explore_data(train_data)\n",
    "\n",
    "# Cleaning the training data\n",
    "train_data = clean_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebcb36-1513-4ca6-8bba-d47f3840c229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
